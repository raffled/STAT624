---
title: "Data in D&R"
author: "jharner"
date: "March 1, 2015"
output: html_document
---

## Key-Value Pairs

In D&R, data is partitioned into subsets. Each subset is represented as a *key-value pair*. Collections of key-value pairs are *distributed data objects (ddo)*, or if the values are data frames, *distributed data frames (ddf)*, and form the basic input and output types for all D&R operations. 

### Key-value pairs in datadr

In `datadr`, key-value pairs are R lists with two elements, one for the key and one for the value. 

```{r}
# simple key-value pair example
list(1:5, rnorm(10))
```

A key is used as a unique identifier for the value. For `datadr` make the key a simple string when possible.

### Key-value pair collections

D&R data objects are made up of collections of key-value pairs. In `datadr`, these are represented as lists of key-value pair lists.

Consider the iris data set, which consists of measurements of 4 aspects for 50 flowers from each of 3 species of iris. Suppose we would like to split the data into key-value pairs by species. We can do this by passing key-value pairs to a function `kvPairs()`:
```{r}
# create by-species key-value pairs
library(datadr)
irisKV <- kvPairs(
   list("setosa", subset(iris, Species == "setosa")),
   list("versicolor", subset(iris, Species == "versicolor")),
   list("virginica", subset(iris, Species == "virginica"))
)
irisKV
```

The result is a list of 3 key-value pairs. We chose the species to be the key and the corresponding data frame to be the value for each pair.

`kvPairs()` is basically a wrapper for `list()`. It checks to make sure key-value pairs are valid and makes sure they are printed nicely. In pratice we actually very rarely need specify key-value pairs like this, but this is useful for illustration.

This example shows how we can partition our data into key-value pairs that have meaning -- each subset represents measurements for one species. The ability to divide the data up into pieces allows us to distribute datasets that might be too large for a single disk across multiple machines, and also allows us to distribute computation, because in D&R we apply methods independently to each subset.

Here, we manually created the partition by species, but `datadr` provides simple mechanisms for specifying divisions, which we will cover later in the tutorial. Prior to doing that, however, we need to discuss how collections of key-value pairs are represented in `datadr` as distributed data objects.

## Distributed Data Objects

In `datadr`, a collection of key-value pairs along with attributes about the collection constitute a distributed data object (ddo). Most `datadr` operations require a ddo, and hence it is important to represent key-value pair collections as such.

### Initializing a ddo

To initialize a collection of key-value pairs as a distributed data object, we use the `ddo()` function:
```{r}
# create ddo object from irisKV
irisDdo <- ddo(irisKV)
```

`ddo()` simply takes the collection of key-value pairs and attaches additional attributes to the resulting ddo object. Note that in this example, since the data is in memory, we are supplying the data directly as the argument to `ddo()`. For larger datasets stored in more scalable backends, instead of passing the data directly, a connection that points to where the key-value pairs are stored is provided.

Objects of class `ddo` have several methods that can be invoked on them. The most simple of these is a print method:
```{r}
irisDdo
```

From the printout of `irisDdo`, we see that a ddo has several attributes. The most basic ones:  

* size (object): The total size of the all of the data as represented in memory in R is 12.67 KB (that's some big data!)   
* size (stored): With backends other than in-memory, the size of data serialized and possibly compressed to disk can be very different from object size, which is useful to know. In this case, it's the same since the object is in memory.   
* \# subsets: There are 3 subsets (one for each species)  

We can look at the keys with:
```{r}
# look at irisDdo keys
getKeys(irisDdo)
```

We can also get an example key-value pair:
```{r}
# look at an example key-value pair of irisDdo
kvExample(irisDdo)
```

`kvExample` is useful for obtaining a subset key-value pair against which we can test out different analytical methods before applying them across the entire data set.

Another attribute, `splitSizeDistn` is empty. This attribute provides information about the quantiles of the distribution of the size of each division. With very large data sets with a large number of subsets, this can be useful for getting a feel for how uniform the subset sizes are.

The `splitSizeDistn` attribute and more that we will see in the future are not computed by default when `ddo()` is called. This is because it requires a computation over the data set, which can take some time with very large datasets, and may not always be desired or necessary.

### Updating attributes

If you decide at any point that you would like to update the attributes of your ddo, you can call:
```{r}
# update irisDdo attributes
irisDdo <- updateAttributes(irisDdo)
irisDdo
```

The splitSizeDistn attribute is now available. We can look at it with the accessor `splitSizeDistn()`:
```{r}
# plot distribution of the size of the key-value pairs
library(ggplot2)
qplot(y = splitSizeDistn(irisDdo), xlab = "percentile", ylab = "subset size (kb)")
```

Another way to get updated attributes is at the time the ddo is created, by setting `update = TRUE`:
```{r}
# update at the time ddo() is called
irisDdo <- ddo(irisKV, update = TRUE)
```

### Note about storage and computation

Notice the first line of output from the `irisDdo` object printout. It states that the object is backed by a "kvMemory" (key-value pairs in memory) connection.

We will talk about other backends for storing and processing larger data sets that don't fit in memory or even on your workstation's disk. The key here is that the interface always stays the same, regardless of whether we are working with terabytes or kilobytes of data.

### Accessing subsets

We can access subsets of the data by key or by index:
```{r}
irisDdo[["setosa"]]
irisDdo[[1]]
irisDdo[c("setosa", "virginica")]
irisDdo[1:2]
```

Accessing by key is much simpler when the key is a character string, but subsetting works even when passing a list of non-string keys.

## Distributed Data Frames

Key-value pairs in distributed data objects can have any structure. If we constrain the values to be data frames or readily transformable into data frames, we can represent the object as a distributed data frame (ddf). A ddf is a ddo with additional attributes. Having a uniform data frame structure for the values provides several benefits and data frames are required for specifying division methods.

### Initializing a ddf

Our `irisKV` data we created earlier has values that are data frames, so we can cast it as a distributed data frame like this:
```{r}
# create ddf object from irisKV
irisDdf <- ddf(irisKV, update = TRUE)
irisDdf
```

### ddf attributes

The printout of `irisDdf` above shows the ddo attributes we saw previously (because every ddf is also a ddo), but we also see some new data-frame-related attributes (which were automatically updated because we specified `update = TRUE`). These include:  

* `names`: a list of the variables  
* `nrow`: the total number of rows in the data set  

There are additional "other" attributes listed at the bottom. The `summary` attribute can be useful for getting an initial look at the variables in your ddf, and is sometimes required for later computations, such as quantile estimation with `drQuantile()`, where the range of a variable is required to get a good quantile approximation. Summary statistics are all computed simultaneously in one MapReduce job with a call to `updateAttributes()`.

The numerical summary statistics are computed using a numerically stable algorithm.

Summary statistics include:

For each numeric variable:   

* `nna`: number of missing values  
* `stats`: list of mean, variance, skewness, kurtosis  
* `range`: min, max  

For each categorical variable:  

* `nobs`: number of observations  
* `nna`: number of missing values  
* `freqTable`: a data frame containing a frequency table  

Summaries can be accessed by:
```{r}
# look at irisDdf summary stats
summary(irisDdf)
```

For categorical variables, the top four values and their frequency is printed. To access the values themselves, we can do, for example:
```{r}
summary(irisDdf)$Sepal.Length$stats
summary(irisDdf)$Species$freqTable
```

### Data frame-like "ddf" methods

With an object of class "ddf", you can use some of the methods that apply to regular data frames:
```{r}
nrow(irisDdf)
ncol(irisDdf)
names(irisDdf)
```

However, `datadr` does not go too far beyond this in terms of making a ddf feel or behave exactly like a regular R data frame.

### Passing a data frame to `ddo()` and `ddf()`

It is possible to pass a single data frame to `ddo()` or `ddf()`. The result is a single key-value pair with the data frame as the value, and "" as the key. This is an option strictly for convenience and with the idea that further down the line operations will be applied that split the data up into a more useful set of key-value pairs. Here is an example:
```{r}
# initialize ddf from a data frame
irisDf <- ddf(iris, update = TRUE)
irisDf
```

This of course only makes sense for data small enough to fit in memory in the first place.

## ddo/ddf Transformations

A very common thing to want to do to a ddo or ddf is apply a transformation to each of the subsets. For example we may want to apply a transformation that:  

* adds a new derived variable to a subset of a ddf
* applies a statistical method or summarization to each subset
* coerces each subset into a data frame

This will be a routine thing to do when we start talking about D&R operations.

We can add transformations to a ddo/ddf using `addTransform()`. Let's look at an example. Recall the iris data split by species:
```{r}
# iris ddf by Species
irisKV <- kvPairs(
   list("setosa", subset(iris, Species == "setosa")),
   list("versicolor", subset(iris, Species == "versicolor")),
   list("virginica", subset(iris, Species == "virginica"))
)
irisDdf <- ddf(irisKV)
```

Suppose we want to add a simple transformation that computes the mean sepal width for each subset. I can do this with the following:
```{r}
irisSL <- addTransform(irisDdf, function(x) mean(x$Sepal.Width))
```

I simply provide my input ddo/ddf `irisDdf` and specify the function I want to apply to each subset. If the function I provide has two arguments, it will pass both the key and value of the current subset as arguments to the function. If it has one argument, it will pass just the value. In this case, it has one argument, so I can expect `x` inside my function to hold the data frame value for a subset of `irisDdf`. Note that I can pre-define this function:
```{r}
meanSL <- function(x) mean(x$Sepal.Width)
irisSL <- addTransform(irisDdf, meanSL)
irisSL
```

Our input data was a ddf, but the output is a ddo! What is in the output?
```{r}
irisSL[[1]]
irisSL[[2]]
```

We see that `irisSL` now holds the data that we would expect -- the result of our transformation -- the mean sepal length. This value is not a data frame, so `irisSL` is a ddo.

The object size is still the same as our input data, `irisDdf`. This is because when you add a transformation to a ddo/ddf, the transformation is not applied immediately, but is deferred until a data operation is applied. Data operations include `divide()`, `recombine()`, `drJoin()`, `drLapply()`, `drFilter()`, `drSample{}`, and `drSubset()`. When any of these are invoked on an object with a transformation attached to it, the transformation will be applied prior to any other computation. The transformation will also be applied any time a subset of the data is requested. Thus although the data has not been physically transformed after a call of `addTransform()`, we can think of it conceptually as already being transformed.

When `addTransform` is called, it is tested on a subset of the data to make sure we have all of the necessary global variables and packages loaded necessary to portably perform the transformation. If there are any package dependencies, it makes a note and stores this information with the object. Also if there are any global object dependencies, these are also stored with the object. So whatever objects exist at the time of applying the transformation, any subsequent changes to the object or removal of the object will not effect the transformation.

For example, consider the following:
```{r}
# set a global variable
globalVar <- 7
# define a function that depends on this global variable
meanSLplus7 <- function(x) mean(x$Sepal.Width) + globalVar
# add this transformation to irisDdf
irisSLplus7 <- addTransform(irisDdf, meanSLplus7)
# look at the first key-value pair (invokes transformation)
irisSLplus7[[1]]
# remove globalVar
rm(globalVar)
# look at the first key-value pair (invokes transformation)
irisSLplus7[[1]]
```

We still get a result even though the global dependency of `meanSLplus7()` has been removed.

A final note about `addTransform()`: it is possible to add multiple transformations to a distributed data object, in which case they are applied in the order supplied, but only one transform should ever be necessary.

## Common Data Operations

The majority of this documentation will cover division and recombination, but here, we present some methods that are available for common data operations that come in handy for manipulating data in various ways.

### drLapply

It is convenient to be able use the familiar `lapply()` approach to apply a function to each key-value pair. An `lapply()` method, called `drLapply()` is available for ddo/ddf objects. The function you specify follows the same convention as described earlier (if it has one argument, it is applied to the value only, if it has two arguments, it is applied to the key and value). A ddo is returned.

Here is an example of using drLapply() to the irisDdf data:
```{r}
# get the mean Sepal.Width for each key-value pair in irisDdf
means <- drLapply(irisDdf, function(x) mean(x$Sepal.Width))
# turn the resulting ddo into a list
as.list(means)
```

### drFilter

A `drFilter()` function is available which takes a function that is applied to each key-value pair. If the function returns TRUE, that key-value pair will be included in the resulting ddo/ddf, if FALSE, it will not.

Here is an example that keeps all subsets with mean sepal width less than 3:
```{r}
# keep subsets with mean sepal width less than 3
drFilter(irisDdf, function(v) mean(v$Sepal.Width) < 3)
```

### drJoin

The `drJoin()` operation takes multiple input ddo/ddf objects and merges their values by key. This is a very useful function when there are multiple input sources that you would like to group together.

Suppose with the iris data that we have two separate input sources, one that reports the sepal width and another that reports the sepal length for each species:
```{r}
# create two new ddo objects that contain sepal width and sepal length
sw <- drLapply(irisDdf, function(x) x$Sepal.Width)
sl <- drLapply(irisDdf, function(x) x$Sepal.Length)
```

An example subset of sw looks like this:
```{r}
sw[[1]]
```

Both `sw` and `sl` have the same set of keys, and the value is a vector of either the sepal width or length. To join them together, we can call `drJoin()`. This function takes any number of ddo/ddf inputs, and they must be named. It also optionally takes a `postTransFn` argument, which allows a transformation function to be applied the joined result.

By default, `drJoin()` groups the various data sources by key, and the resulting value is a named list, where each element of the list is the value from each data source. For example, to join the sw and sl data, we get the following:
```{r}
# join sw and sl by key
joinRes <- drJoin(Sepal.Width = sw, Sepal.Length = sl)
# look at first key-value pair
joinRes[[1]]
```

### drSample

It can be useful to create a new data set of randomly sampled subsets of a large data set. The `drSample()` function provides for this. Currently, it is as simple as specifying the fraction of subsets you would like the resulting data set to have:
```{r}
set.seed(1234)
drSample(irisDdf, fraction = 0.25)
```
